{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# This Kernel was copied from the Kernel \"Keras Classifier\" from Mitch Ailey\n",
    "#\n",
    "\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras import callbacks\n",
    "import os\n",
    "import cv2\n",
    "import string\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "a2d3b46d9a967f98339ebaecbbdad3d0b5e8883c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train  308\n"
     ]
    }
   ],
   "source": [
    "print('Train ',len(os.listdir(\"../input/kaggle/Train\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "#Init main values\n",
    "symbols = string.ascii_lowercase + \"0123456789\" # All symbols captcha can contain\n",
    "num_symbols = len(symbols)\n",
    "print(num_symbols)\n",
    "img_shape = (50, 200, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "50e6b69ebc290e5c61c3eab5c90c1fbf44da93fc"
   },
   "outputs": [],
   "source": [
    "# Define a function that creates a net\n",
    "def create_net():\n",
    "    img = layers.Input(shape=img_shape) # Get image as an input and process it through some Convs\n",
    "    conv1 = layers.Conv2D(16, (3, 3), padding='same', activation='relu')(img)\n",
    "    mp1 = layers.MaxPooling2D(padding='same')(conv1)  # 100x25\n",
    "    conv2 = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(mp1)\n",
    "    mp2 = layers.MaxPooling2D(padding='same')(conv2)  # 50x13\n",
    "    conv3 = layers.Conv2D(32, (3, 3), padding='same', activation='relu')(mp2)\n",
    "    bn = layers.BatchNormalization()(conv3)\n",
    "    mp3 = layers.MaxPooling2D(padding='same')(bn)  # 25x7\n",
    "    \n",
    "    # Get flattened vector and make 4 branches from it. Each branch will predict one letter\n",
    "    flat = layers.Flatten()(mp3)\n",
    "    outs = []\n",
    "    for _ in range(4):\n",
    "        dens1 = layers.Dense(64, activation='relu')(flat)\n",
    "        drop = layers.Dropout(0.5)(dens1)\n",
    "        res = layers.Dense(num_symbols, activation='sigmoid')(drop)\n",
    "\n",
    "        outs.append(res)\n",
    "    \n",
    "    # Compile model and return it\n",
    "    model = Model(img, outs)\n",
    "    model.compile('rmsprop', loss=['categorical_crossentropy', 'categorical_crossentropy',\n",
    "                                   'categorical_crossentropy', 'categorical_crossentropy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "5bb3e7e0260ae83a8a46b1420061b295c159110a"
   },
   "outputs": [],
   "source": [
    "# First we need to preprocess the data\n",
    "def preprocess_data():\n",
    "    n_samples = len(os.listdir('../input/kaggle/Train'))\n",
    "    X = np.zeros((n_samples, 50, 200, 1))\n",
    "    y = np.zeros((4, n_samples, num_symbols))\n",
    "\n",
    "    for i, pic in enumerate(os.listdir('../input/kaggle/Train')):\n",
    "        # Read image as grayscale\n",
    "        img = cv2.imread(os.path.join('../input/kaggle/Train', pic), cv2.IMREAD_GRAYSCALE)\n",
    "        pic_target = pic[:-4]\n",
    "        if len(pic_target) < 5:\n",
    "            # Scale and reshape image\n",
    "            img = img / 255.\n",
    "            img = np.reshape(img, (50, 200, 1))\n",
    "            \n",
    "            # Define targets and code them using OneHotEncoding\n",
    "            targs = np.zeros((4, num_symbols))\n",
    "            for j, l in enumerate(pic_target):\n",
    "                ind = symbols.find(l)\n",
    "                targs[j, ind] = 1\n",
    "            X[i] = img\n",
    "            y[:, i] = targs\n",
    "    \n",
    "    # Return final data\n",
    "    return X, y\n",
    "\n",
    "X, y = preprocess_data()\n",
    "X_train, y_train = X[:250], y[:, :250]\n",
    "X_test, y_test = X[250:], y[:, 250:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "4ac35762e4b2a8602b4ff1768a108a60058e6c4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 50 samples\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 3s 15ms/step - loss: 15.9480 - dense_2_loss: 3.9693 - dense_4_loss: 4.0907 - dense_6_loss: 3.8912 - dense_8_loss: 3.9968 - val_loss: 15.4953 - val_dense_2_loss: 3.6360 - val_dense_4_loss: 4.2488 - val_dense_6_loss: 3.8627 - val_dense_8_loss: 3.7479\n",
      "Epoch 2/30\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 14.4481 - dense_2_loss: 3.5914 - dense_4_loss: 3.6479 - dense_6_loss: 3.5981 - dense_8_loss: 3.6106 - val_loss: 14.7344 - val_dense_2_loss: 3.6291 - val_dense_4_loss: 3.8997 - val_dense_6_loss: 3.5960 - val_dense_8_loss: 3.6096\n",
      "Epoch 3/30\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 14.3441 - dense_2_loss: 3.5505 - dense_4_loss: 3.5871 - dense_6_loss: 3.5837 - dense_8_loss: 3.6228 - val_loss: 14.7620 - val_dense_2_loss: 3.5583 - val_dense_4_loss: 3.8243 - val_dense_6_loss: 3.7368 - val_dense_8_loss: 3.6427\n",
      "Epoch 4/30\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 14.3178 - dense_2_loss: 3.5385 - dense_4_loss: 3.5670 - dense_6_loss: 3.6145 - dense_8_loss: 3.5977 - val_loss: 14.7832 - val_dense_2_loss: 3.5839 - val_dense_4_loss: 3.8302 - val_dense_6_loss: 3.7276 - val_dense_8_loss: 3.6415\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 14.1211 - dense_2_loss: 3.4718 - dense_4_loss: 3.5585 - dense_6_loss: 3.5286 - dense_8_loss: 3.5622 - val_loss: 14.6238 - val_dense_2_loss: 3.6355 - val_dense_4_loss: 3.6323 - val_dense_6_loss: 3.7095 - val_dense_8_loss: 3.6466\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 14.1131 - dense_2_loss: 3.4442 - dense_4_loss: 3.5592 - dense_6_loss: 3.5427 - dense_8_loss: 3.5671 - val_loss: 14.5124 - val_dense_2_loss: 3.7031 - val_dense_4_loss: 3.6645 - val_dense_6_loss: 3.5828 - val_dense_8_loss: 3.5619\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 13.9502 - dense_2_loss: 3.4523 - dense_4_loss: 3.4999 - dense_6_loss: 3.4660 - dense_8_loss: 3.5319 - val_loss: 15.3772 - val_dense_2_loss: 3.9675 - val_dense_4_loss: 3.6437 - val_dense_6_loss: 4.0721 - val_dense_8_loss: 3.6938\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 13.9882 - dense_2_loss: 3.3942 - dense_4_loss: 3.5474 - dense_6_loss: 3.5234 - dense_8_loss: 3.5232 - val_loss: 15.2736 - val_dense_2_loss: 3.8796 - val_dense_4_loss: 3.6729 - val_dense_6_loss: 3.8174 - val_dense_8_loss: 3.9037\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 13.8388 - dense_2_loss: 3.4001 - dense_4_loss: 3.4725 - dense_6_loss: 3.4675 - dense_8_loss: 3.4987 - val_loss: 14.9704 - val_dense_2_loss: 3.6301 - val_dense_4_loss: 3.6486 - val_dense_6_loss: 3.8964 - val_dense_8_loss: 3.7954\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 13.6429 - dense_2_loss: 3.3259 - dense_4_loss: 3.4357 - dense_6_loss: 3.4314 - dense_8_loss: 3.4498 - val_loss: 14.7656 - val_dense_2_loss: 3.5678 - val_dense_4_loss: 3.7375 - val_dense_6_loss: 3.7683 - val_dense_8_loss: 3.6920\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 13.4853 - dense_2_loss: 3.2890 - dense_4_loss: 3.4015 - dense_6_loss: 3.3635 - dense_8_loss: 3.4313 - val_loss: 15.0442 - val_dense_2_loss: 3.6339 - val_dense_4_loss: 3.7642 - val_dense_6_loss: 4.0232 - val_dense_8_loss: 3.6229\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 13.4748 - dense_2_loss: 3.3098 - dense_4_loss: 3.4431 - dense_6_loss: 3.3346 - dense_8_loss: 3.3874 - val_loss: 15.3276 - val_dense_2_loss: 3.9559 - val_dense_4_loss: 3.7657 - val_dense_6_loss: 3.9405 - val_dense_8_loss: 3.6654\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 13.3516 - dense_2_loss: 3.2343 - dense_4_loss: 3.3634 - dense_6_loss: 3.3518 - dense_8_loss: 3.4021 - val_loss: 15.0170 - val_dense_2_loss: 3.8062 - val_dense_4_loss: 3.7393 - val_dense_6_loss: 3.7607 - val_dense_8_loss: 3.7108\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 13.2341 - dense_2_loss: 3.2512 - dense_4_loss: 3.3215 - dense_6_loss: 3.3017 - dense_8_loss: 3.3597 - val_loss: 15.7391 - val_dense_2_loss: 4.0205 - val_dense_4_loss: 3.8522 - val_dense_6_loss: 3.9364 - val_dense_8_loss: 3.9300\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 13.0002 - dense_2_loss: 3.1437 - dense_4_loss: 3.2974 - dense_6_loss: 3.2796 - dense_8_loss: 3.2796 - val_loss: 17.5181 - val_dense_2_loss: 4.0551 - val_dense_4_loss: 4.4032 - val_dense_6_loss: 4.0482 - val_dense_8_loss: 5.0117\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 12.8391 - dense_2_loss: 3.1141 - dense_4_loss: 3.2387 - dense_6_loss: 3.2176 - dense_8_loss: 3.2687 - val_loss: 16.5531 - val_dense_2_loss: 4.2090 - val_dense_4_loss: 3.8389 - val_dense_6_loss: 3.9784 - val_dense_8_loss: 4.5268\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 12.5587 - dense_2_loss: 3.0851 - dense_4_loss: 3.1844 - dense_6_loss: 3.1426 - dense_8_loss: 3.1466 - val_loss: 16.6040 - val_dense_2_loss: 3.9128 - val_dense_4_loss: 3.9661 - val_dense_6_loss: 4.4296 - val_dense_8_loss: 4.2955\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 12.4276 - dense_2_loss: 3.0169 - dense_4_loss: 3.1464 - dense_6_loss: 3.1039 - dense_8_loss: 3.1605 - val_loss: 17.1573 - val_dense_2_loss: 4.0922 - val_dense_4_loss: 4.2002 - val_dense_6_loss: 4.5912 - val_dense_8_loss: 4.2736\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 12.2311 - dense_2_loss: 2.9557 - dense_4_loss: 3.0549 - dense_6_loss: 3.0724 - dense_8_loss: 3.1481 - val_loss: 16.3459 - val_dense_2_loss: 4.0208 - val_dense_4_loss: 3.9164 - val_dense_6_loss: 4.4334 - val_dense_8_loss: 3.9754\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 11.9527 - dense_2_loss: 2.8578 - dense_4_loss: 3.0635 - dense_6_loss: 3.0249 - dense_8_loss: 3.0065 - val_loss: 17.3926 - val_dense_2_loss: 4.9017 - val_dense_4_loss: 3.9594 - val_dense_6_loss: 4.4596 - val_dense_8_loss: 4.0719\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 11.9469 - dense_2_loss: 2.9428 - dense_4_loss: 3.0326 - dense_6_loss: 3.0097 - dense_8_loss: 2.9618 - val_loss: 17.5225 - val_dense_2_loss: 4.3211 - val_dense_4_loss: 4.4332 - val_dense_6_loss: 4.4407 - val_dense_8_loss: 4.3275\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 11.5250 - dense_2_loss: 2.8073 - dense_4_loss: 2.9636 - dense_6_loss: 2.9148 - dense_8_loss: 2.8393 - val_loss: 23.6823 - val_dense_2_loss: 6.1888 - val_dense_4_loss: 6.4001 - val_dense_6_loss: 5.7819 - val_dense_8_loss: 5.3115\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 11.3059 - dense_2_loss: 2.7992 - dense_4_loss: 2.8885 - dense_6_loss: 2.7912 - dense_8_loss: 2.8269 - val_loss: 20.1498 - val_dense_2_loss: 4.8387 - val_dense_4_loss: 5.3453 - val_dense_6_loss: 5.4126 - val_dense_8_loss: 4.5532\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 11.0963 - dense_2_loss: 2.6643 - dense_4_loss: 2.8780 - dense_6_loss: 2.7628 - dense_8_loss: 2.7911 - val_loss: 18.1795 - val_dense_2_loss: 4.4837 - val_dense_4_loss: 4.5679 - val_dense_6_loss: 4.5310 - val_dense_8_loss: 4.5969\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 11.0210 - dense_2_loss: 2.6644 - dense_4_loss: 2.8085 - dense_6_loss: 2.7769 - dense_8_loss: 2.7712 - val_loss: 27.1767 - val_dense_2_loss: 7.5606 - val_dense_4_loss: 6.7834 - val_dense_6_loss: 6.9424 - val_dense_8_loss: 5.8904\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 10.6232 - dense_2_loss: 2.6095 - dense_4_loss: 2.6763 - dense_6_loss: 2.6896 - dense_8_loss: 2.6477 - val_loss: 29.9555 - val_dense_2_loss: 8.0925 - val_dense_4_loss: 7.5051 - val_dense_6_loss: 7.7113 - val_dense_8_loss: 6.6466\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 10.5325 - dense_2_loss: 2.4777 - dense_4_loss: 2.7553 - dense_6_loss: 2.6557 - dense_8_loss: 2.6438 - val_loss: 30.2045 - val_dense_2_loss: 8.8791 - val_dense_4_loss: 6.8310 - val_dense_6_loss: 7.7297 - val_dense_8_loss: 6.7648\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 10.1062 - dense_2_loss: 2.4592 - dense_4_loss: 2.6724 - dense_6_loss: 2.4527 - dense_8_loss: 2.5218 - val_loss: 26.3392 - val_dense_2_loss: 6.7205 - val_dense_4_loss: 6.6104 - val_dense_6_loss: 7.1474 - val_dense_8_loss: 5.8609\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 9.8057 - dense_2_loss: 2.3579 - dense_4_loss: 2.4866 - dense_6_loss: 2.5122 - dense_8_loss: 2.4489 - val_loss: 29.1260 - val_dense_2_loss: 7.5168 - val_dense_4_loss: 7.0121 - val_dense_6_loss: 7.7794 - val_dense_8_loss: 6.8177\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 9.6255 - dense_2_loss: 2.3396 - dense_4_loss: 2.4728 - dense_6_loss: 2.4241 - dense_8_loss: 2.3890 - val_loss: 30.8120 - val_dense_2_loss: 7.1359 - val_dense_4_loss: 8.2774 - val_dense_6_loss: 8.1463 - val_dense_8_loss: 7.2524\n"
     ]
    }
   ],
   "source": [
    "# Create net and fit\n",
    "net = create_net()\n",
    "history = net.fit(X_train, [y_train[0], y_train[1], y_train[2], y_train[3]], batch_size=32, epochs=30, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "8f6c5c1762c8677c3242b76aa4ee1ff0891641fd"
   },
   "outputs": [],
   "source": [
    "# Define function to predict captcha\n",
    "def predict(filepath):\n",
    "    img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE) / 255.\n",
    "    res = np.array(net.predict(img[np.newaxis, :, :, np.newaxis]))\n",
    "    ans = np.reshape(res, (4, 36))\n",
    "    l_ind = []\n",
    "    probs = []\n",
    "    for a in ans:\n",
    "        l_ind.append(np.argmax(a))\n",
    "        probs.append(np.max(a))\n",
    "\n",
    "    capt = ''\n",
    "    for l in l_ind:\n",
    "        capt += symbols[l]\n",
    "    return capt, sum(probs) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "4f4714667d6b95efc02131eb3790270c2bc5e955"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['captcha_mod2_47.png', 'captcha_mod2_43.png', 'captcha_mod2_50.png', 'captcha_mod2_44.png', 'captcha_mod2_42.png', 'captcha_mod2_49.png', 'captcha_mod2_41.png', 'captcha_mod2_40.png', 'captcha_mod2_48.png', 'captcha_mod2_45.png', 'captcha_mod2_39.png', 'captcha_mod2_46.png']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output = os.listdir(\"../input/kaggle/non_identified\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "fb9a513f3e52efb2b30a7075b1ba0e39938b4170"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s 2ms/step\n",
      "captcha_mod2_47.png  - \n",
      "('8ane', 0.3306001517921686)\n",
      "captcha_mod2_43.png  - \n",
      "('8at9', 0.26664652302861214)\n",
      "captcha_mod2_50.png  - \n",
      "('8ate', 0.5319305751472712)\n",
      "captcha_mod2_44.png  - \n",
      "('dgu3', 0.3156154981115833)\n",
      "captcha_mod2_42.png  - \n",
      "('8a63', 0.1838203025981784)\n",
      "captcha_mod2_49.png  - \n",
      "('dan3', 0.3355392157100141)\n",
      "captcha_mod2_41.png  - \n",
      "('e7ti', 0.3960379995405674)\n",
      "captcha_mod2_40.png  - \n",
      "('87j3', 0.1072244131937623)\n",
      "captcha_mod2_48.png  - \n",
      "('eati', 0.24957608431577682)\n",
      "captcha_mod2_45.png  - \n",
      "('eati', 0.34064436983317137)\n",
      "captcha_mod2_39.png  - \n",
      "('etti', 0.41583205317147076)\n",
      "captcha_mod2_46.png  - \n",
      "('8at9', 0.5196103788912296)\n"
     ]
    }
   ],
   "source": [
    "# Check model on some samples\n",
    "net.evaluate(X_test, [y_test[0], y_test[1], y_test[2], y_test[3]])\n",
    "\n",
    "for i in output:\n",
    "    file='../input/kaggle/non_identified/' + i\n",
    "    print(i , ' - ')\n",
    "    print(predict(file))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
